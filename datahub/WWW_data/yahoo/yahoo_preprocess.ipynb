{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/data/projects/kwangeun/CVAR/datahub/WWW_data/yahoo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2604, 2)\n",
      "(2,)\n",
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "text_features_org = np.load(\"./text_features.npy\", allow_pickle=True)\n",
    "print(text_features_org.shape) # num_ids, 2\n",
    "print(text_features_org[0].shape) # id, feature\n",
    "print(text_features_org[0][1].shape) # feature_size\n",
    "text_emb_size = text_features_org[0][1].shape[0]\n",
    "text_features = {f[0]: f[1] for f in text_features_org}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./video_features.pkl\", \"rb\") as pf:\n",
    "    video_features = pickle.load(pf)\n",
    "video_emb_size = list(video_features.values())[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "warm_train = pd.read_csv(\"./warm_train.csv\")\n",
    "cold_val = pd.read_csv(\"./cold_val.csv\")\n",
    "cold_test = pd.read_csv(\"./cold_test.csv\")\n",
    "warm_items = warm_train[\"movielens_id\"].unique()\n",
    "cold_val_items = cold_val[\"movielens_id\"].unique()\n",
    "cold_test_items = cold_test[\"movielens_id\"].unique()\n",
    "all_items = np.concatenate([warm_items, cold_val_items, cold_test_items], axis=0)\n",
    "\n",
    "warm_users = warm_train[\"userId\"].unique()\n",
    "cold_val_users = cold_val[\"userId\"].unique()\n",
    "cold_test_users = cold_test[\"userId\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warm_items: 1802\n",
      "cold_val_items: 402\n",
      "cold_test_items: 400\n"
     ]
    }
   ],
   "source": [
    "print(f\"warm_items: {len(warm_items)}\")\n",
    "print(f\"cold_val_items: {len(cold_val_items)}\")\n",
    "print(f\"cold_test_items: {len(cold_test_items)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implicit feedback with rating\n",
    "threshold = 3.5\n",
    "ratings = pd.read_csv(\"./ratings.csv\")\n",
    "ratings['rating'] = ratings['rating'].map(lambda x: 0 if x < threshold else 1)\n",
    "ratings.rename(columns={\"movielens_id\": \"item_id\", \"userId\": \"user_id\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter items if not in warm and cold\n",
    "ratings = ratings[ratings[\"item_id\"].isin(all_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_features = ratings[[\"item_id\"]].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# append text features\n",
    "text = []\n",
    "for item_id in content_features[\"item_id\"]:\n",
    "    text.append(text_features[item_id])\n",
    "content_features[\"text\"] = text\n",
    "\n",
    "# append video features\n",
    "video = []\n",
    "for item_id in content_features[\"item_id\"]:\n",
    "    try:\n",
    "        video.append(video_features[item_id])\n",
    "    except KeyError:\n",
    "        print(item_id)\n",
    "content_features[\"video\"] = video\n",
    "\n",
    "content_features = {row.item_id: {\"text\": row.text, \"video\": row.video} for row in content_features.itertuples()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # densify index\n",
    "# user_map = {user_id: idx for idx, user_id in enumerate(ratings[\"user_id\"].unique())}\n",
    "# item_map = {item_id: idx for idx, item_id in enumerate(ratings[\"item_id\"].unique())}\n",
    "# ratings[\"user_id\"] = ratings[\"user_id\"].map(user_map)\n",
    "# ratings[\"item_id\"] = ratings[\"item_id\"].map(item_map)\n",
    "\n",
    "# warm_items = np.array([item_map[item] for item in warm_items])\n",
    "# cold_val_items = np.array([item_map[item] for item in cold_val_items])\n",
    "# cold_test_items = np.array([item_map[item] for item in cold_test_items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = [\"user_id\", \"item_id\", \"rating\"]\n",
    "ratings = ratings[orders]\n",
    "description = [\n",
    "    ('user_id', np.max(ratings[\"user_id\"]) + 1, 'spr'),\n",
    "    ('item_id', np.max(ratings[\"item_id\"]) + 1, 'spr'),\n",
    "    ('text', text_emb_size, 'pretrained'),\n",
    "    ('video', video_emb_size, 'pretrained'),\n",
    "    ('rating', 2, 'label'),\n",
    "    ('count', -1, 'ctn'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user2count = ratings.groupby(['item_id']).size().reset_index(name='count').sort_values(by='count')\n",
    "item_ids = list(user2count['item_id'])\n",
    "counts = np.array(user2count['count'])\n",
    "# plt.plot(np.arange(len(counts)), counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess count\n",
    "ratings = ratings.join(user2count.set_index('item_id'), on='item_id')\n",
    "min_count = np.min(ratings['count'])\n",
    "max_count = np.max(ratings['count'])\n",
    "ratings['count'] = ratings['count'].map(lambda x: (x - min_count)/(max_count - min_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warm/cold, train/test/val split is based on item id\n",
    "warm = ratings[ratings[\"item_id\"].isin(warm_items)]\n",
    "warm = warm[warm[\"user_id\"].isin(warm_users)]\n",
    "warm_train, warm_eval = train_test_split(warm, test_size=0.2, stratify=warm[\"rating\"])\n",
    "warm_val, warm_test = train_test_split(warm_eval, test_size=0.5, stratify=warm_eval[\"rating\"])\n",
    "warm_train.reset_index(drop=True, inplace=True)\n",
    "warm_val.reset_index(drop=True, inplace=True)\n",
    "warm_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cold_val = ratings[ratings[\"item_id\"].isin(cold_val_items)]\n",
    "cold_val = cold_val[cold_val[\"user_id\"].isin(cold_val_users)]\n",
    "cold_test = ratings[ratings[\"item_id\"].isin(cold_test_items)]\n",
    "cold_test = cold_test[cold_test[\"user_id\"].isin(cold_test_users)]\n",
    "\n",
    "cold_val = cold_val[cold_val[\"rating\"] > 0]\n",
    "cold_test = cold_test[cold_test[\"rating\"] > 0]\n",
    "cold_val.reset_index(drop=True, inplace=True)\n",
    "cold_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warm_train size: 38750\n",
      "warm_val size: 4844\n",
      "warm_test size: 4844\n",
      "cold_val size: 8357\n",
      "cold_test size: 10163\n",
      "description size: 6\n",
      "content_features size: 2604\n"
     ]
    }
   ],
   "source": [
    "save_dic = {\n",
    "    \"warm_train\": warm_train,\n",
    "    \"warm_val\": warm_val,\n",
    "    \"warm_test\": warm_test,\n",
    "    \"cold_val\": cold_val,\n",
    "    \"cold_test\": cold_test,\n",
    "    \"description\": description,\n",
    "    \"content_features\": content_features,\n",
    "}\n",
    "for name, df in save_dic.items():\n",
    "    print(\"{} size: {}\".format(name, len(df)))\n",
    "with open('./yahoo_data.pkl', 'bw+') as f:\n",
    "    pickle.dump(save_dic, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c6812938163a5641a6c3e8a9f379925be7813a618feb6985f86dc94be9799b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

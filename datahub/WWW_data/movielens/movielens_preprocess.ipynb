{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/data/projects/kwangeun/CVAR/datahub/WWW_data/movielens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4953, 2)\n",
      "(2,)\n",
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "text_features_org = np.load(\"./text_features.npy\", allow_pickle=True)\n",
    "print(text_features_org.shape) # num_ids, 2\n",
    "print(text_features_org[0].shape) # id, feature\n",
    "print(text_features_org[0][1].shape) # feature_size\n",
    "text_emb_size = text_features_org[0][1].shape[0]\n",
    "text_features = {f[0]: f[1] for f in text_features_org}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./video_features.pkl\", \"rb\") as pf:\n",
    "    video_features = pickle.load(pf)\n",
    "video_emb_size = video_features[1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {\n",
    "    \"userId\": \"user_id\",\n",
    "    \"movielens_id\": \"item_id\",\n",
    "}\n",
    "warm_train = pd.read_csv(\"./warm_train.csv\")\n",
    "warm_val = pd.read_csv(\"./warm_val.csv\")\n",
    "cold_val = pd.read_csv(\"./cold_val.csv\")\n",
    "cold_test = pd.read_csv(\"./cold_test.csv\")\n",
    "\n",
    "warm_train.rename(columns=rename_dict, inplace=True)\n",
    "warm_val.rename(columns=rename_dict, inplace=True)\n",
    "cold_val.rename(columns=rename_dict, inplace=True)\n",
    "cold_test.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "warm_train = warm_train[[\"user_id\", \"item_id\", \"rating\"]]\n",
    "warm_val = warm_val[[\"user_id\", \"item_id\", \"rating\"]]\n",
    "cold_val = cold_val[[\"user_id\", \"item_id\", \"rating\"]]\n",
    "cold_test = cold_test[[\"user_id\", \"item_id\", \"rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implicit feedback with rating\n",
    "threshold = 3.5\n",
    "warm_train[\"rating\"] = warm_train[\"rating\"].map(lambda x: 0 if x < threshold else 1)\n",
    "warm_val[\"rating\"] = warm_val[\"rating\"].map(lambda x: 0 if x < threshold else 1)\n",
    "cold_val[\"rating\"] = cold_val[\"rating\"].map(lambda x: 0 if x < threshold else 1)\n",
    "cold_test[\"rating\"] = cold_test[\"rating\"].map(lambda x: 0 if x < threshold else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_neg_ratings(df):\n",
    "    item_seq = df.groupby(\"user_id\")[\"item_id\"].apply(list).reset_index(name=\"item_seq\")\n",
    "    item_seq = {user: seq for user, seq in zip(item_seq[\"user_id\"], item_seq[\"item_seq\"])}\n",
    "    all_items = df[\"item_id\"].unique()\n",
    "\n",
    "    for user_id in tqdm(df[\"user_id\"].unique()):\n",
    "        pos_items = item_seq[user_id]\n",
    "        num_pos = len(pos_items)\n",
    "        candidate = [item for item in all_items if item not in pos_items]\n",
    "\n",
    "        user = np.repeat(user_id, num_pos)\n",
    "        neg_ratings = np.repeat(0, num_pos)\n",
    "        neg_items = np.random.choice(candidate, num_pos, replace=False)\n",
    "\n",
    "        neg_records = pd.DataFrame({\n",
    "            \"user_id\": user,\n",
    "            \"item_id\": neg_items,\n",
    "            \"rating\": neg_ratings\n",
    "        })\n",
    "\n",
    "        df = pd.concat([df, neg_records], axis=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27993/27993 [02:17<00:00, 204.03it/s]\n"
     ]
    }
   ],
   "source": [
    "warm_train = generate_neg_ratings(warm_train)\n",
    "warm_val = generate_neg_ratings(warm_val)\n",
    "cold_val = generate_neg_ratings(cold_val)\n",
    "cold_test = generate_neg_ratings(cold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warm_train.to_csv(\"./warm_train_with_negative.csv\", index=False)\n",
    "# warm_val.to_csv(\"./warm_val_with_negative.csv\", index=False)\n",
    "# cold_val.to_csv(\"./cold_val_with_negative.csv\", index=False)\n",
    "# cold_test.to_csv(\"./cold_test_with_negative.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "warm_train = pd.read_csv(\"./warm_train_with_negative.csv\")\n",
    "warm_val = pd.read_csv(\"./warm_val_with_negative.csv\")\n",
    "cold_val = pd.read_csv(\"./cold_val_with_negative.csv\")\n",
    "cold_test = pd.read_csv(\"./cold_test_with_negative.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warm_items: 4198\n",
      "cold_val_items: 378\n",
      "cold_test_items: 377\n"
     ]
    }
   ],
   "source": [
    "warm_items = warm_train[\"item_id\"].unique()\n",
    "cold_val_items = cold_val[\"item_id\"].unique()\n",
    "cold_test_items = cold_test[\"item_id\"].unique()\n",
    "all_items = np.concatenate([warm_items, cold_val_items, cold_test_items], axis=0)\n",
    "\n",
    "print(f\"warm_items: {len(warm_items)}\")\n",
    "print(f\"cold_val_items: {len(cold_val_items)}\")\n",
    "print(f\"cold_test_items: {len(cold_test_items)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1619534\n",
      "0    1619534\n",
      "Name: rating, dtype: int64\n",
      "1    202400\n",
      "0    202400\n",
      "Name: rating, dtype: int64\n",
      "1    496130\n",
      "0    496130\n",
      "Name: rating, dtype: int64\n",
      "1    659783\n",
      "0    659783\n",
      "Name: rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(warm_train[\"rating\"].value_counts())\n",
    "print(warm_val[\"rating\"].value_counts())\n",
    "print(cold_val[\"rating\"].value_counts())\n",
    "print(cold_test[\"rating\"].value_counts())\n",
    "\n",
    "print(warm_train[[\"user_id\", \"item_id\"]].duplicated().sum())\n",
    "print(warm_val[[\"user_id\", \"item_id\"]].duplicated().sum())\n",
    "print(cold_val[[\"user_id\", \"item_id\"]].duplicated().sum())\n",
    "print(cold_test[[\"user_id\", \"item_id\"]].duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_features = pd.DataFrame(all_items, columns=[\"item_id\"])\n",
    "\n",
    "# append text features\n",
    "text = []\n",
    "for item_id in content_features[\"item_id\"]:\n",
    "    text.append(text_features[item_id])\n",
    "content_features[\"text\"] = text\n",
    "\n",
    "# append video features\n",
    "video = []\n",
    "for item_id in content_features[\"item_id\"]:\n",
    "    video.append(video_features[item_id])\n",
    "content_features[\"video\"] = video\n",
    "\n",
    "content_features = {row.item_id: {\"text\": row.text, \"video\": row.video} for row in content_features.itertuples()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ratings = pd.concat([warm_train, warm_val, cold_test, cold_val])\n",
    "orders = [\"user_id\", \"item_id\", \"rating\"]\n",
    "description = [\n",
    "    ('user_id', np.max(all_ratings[\"user_id\"]) + 1, 'spr'),\n",
    "    ('item_id', np.max(all_ratings[\"item_id\"]) + 1, 'spr'),\n",
    "    ('text', text_emb_size, 'pretrained'),\n",
    "    ('video', video_emb_size, 'pretrained'),\n",
    "    ('rating', 2, 'label'),\n",
    "    ('count', -1, 'ctn'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_count(df):\n",
    "    user2count = df.groupby(['item_id']).size().reset_index(name='count').sort_values(by='count')\n",
    "    item_ids = list(user2count['item_id'])\n",
    "    counts = np.array(user2count['count'])\n",
    "\n",
    "    df = df.join(user2count.set_index('item_id'), on='item_id')\n",
    "    min_count = np.min(df['count'])\n",
    "    max_count = np.max(df['count'])\n",
    "    df['count'] = df['count'].map(lambda x: (x - min_count)/(max_count - min_count))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "warm_train = add_count(warm_train)\n",
    "warm_val = add_count(warm_val)\n",
    "cold_val = add_count(cold_val)\n",
    "cold_test = add_count(cold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warm_train size: 3239068\n",
      "warm_val size: 404800\n",
      "cold_val size: 992260\n",
      "cold_test size: 1319566\n",
      "description size: 6\n",
      "content_features size: 4953\n"
     ]
    }
   ],
   "source": [
    "save_dic = {\n",
    "    \"warm_train\": warm_train,\n",
    "    \"warm_val\": warm_val,\n",
    "    \"cold_val\": cold_val,\n",
    "    \"cold_test\": cold_test,\n",
    "    \"description\": description,\n",
    "    \"content_features\": content_features,\n",
    "}\n",
    "for name, df in save_dic.items():\n",
    "    print(\"{} size: {}\".format(name, len(df)))\n",
    "with open('./movielens_data.pkl', 'bw+') as f:\n",
    "    pickle.dump(save_dic, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c6812938163a5641a6c3e8a9f379925be7813a618feb6985f86dc94be9799b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
